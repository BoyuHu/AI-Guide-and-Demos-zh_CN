{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f01cd25-5a0f-40d5-a48f-990022340c09",
   "metadata": {},
   "source": [
    "# 简介\n",
    "\n",
    "> 指导文章：[01. 初识 LLM API：环境配置与多轮对话演示](https://github.com/Hoper-J/LLM-Guide-and-Demos/blob/master/Guide/01.%20初识%20LLM%20API：环境配置与多轮对话演示.md)\n",
    "\n",
    "在这个 Notebook 中，我们将展示如何使用大语言模型（LLM）API，通过简单的 API 调用，演示如何与大模型进行交互。这是对 API 基础使用的一个演示，不涉及构建 AI 应用。\n",
    "\n",
    "在线链接：[Kaggle](https://www.kaggle.com/code/aidemos/01-llm-api) | [Colab](https://colab.research.google.com/drive/1jFC_WIec7KW08GBxHuEHikcXWbbv3gSh?usp=share_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9688f10-a828-498a-ae34-2458372eeac0",
   "metadata": {},
   "source": [
    "# 环境变量配置\n",
    "\n",
    "为了保护API密钥的安全，我们需要将其设置为环境变量。环境变量允许我们在不将敏感信息写入代码的情况下访问它们。\n",
    "\n",
    "你可以通过两种方式之一来设置环境变量：\n",
    "1. 在终端中设置环境变量。\n",
    "2. 在 Python 脚本中设置环境变量。\n",
    "\n",
    "这里我们直接在 Python 中进行设置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcc60ff-c2f1-4a4d-89ba-703ce064aa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 设置DASHSCOPE_API_KEY为你的API密钥\n",
    "os.environ['OPENAI_API_KEY'] = 'your-api-key'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde759d2-84d8-47d8-afb9-b60eb8b8c8c8",
   "metadata": {},
   "source": [
    "# 获取环境变量\n",
    "\n",
    "使用 `os.getenv()` 函数来获取环境变量的值，这样我们可以在代码中安全地访问API密钥。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2537743-ddf7-409f-a0b7-9907fc3c171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取API密钥\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# 打印密钥以确认它被成功读取\n",
    "print(api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa90edf1-6557-4d2e-bc9f-0cd32ee2399a",
   "metadata": {},
   "source": [
    "# 安装所需库\n",
    "\n",
    "接下来，我们需要安装openai库，用于与阿里云的大模型API进行交互。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8861d904-182e-459b-8d68-bcb643d11615",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bec3a1-907b-45f8-b86f-e76dfbd11838",
   "metadata": {},
   "source": [
    "# 单轮对话演示\n",
    "\n",
    "在这一部分，我们将通过API调用构建一个简单的单轮对话，你可以输入一个问题，模型将会返回一个响应。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32ed729-5af0-41f1-bba5-ca31b04b833e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# 定义函数来获取模型响应\n",
    "def get_response():\n",
    "    client = OpenAI(\n",
    "        api_key=os.getenv('OPENAI_API_KEY'),  # 获取环境变量中的API密钥\n",
    "        base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",  # 使用阿里云大模型API\n",
    "    )\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"qwen-turbo\",\n",
    "        messages=[\n",
    "            {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "            {'role': 'user', 'content': '你是谁？'}\n",
    "        ]\n",
    "    )\n",
    "    print(completion.model_dump_json())\n",
    "\n",
    "# 调用函数进行对话\n",
    "get_response()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bca8c3f-bde7-404e-ba2b-2180c3d62118",
   "metadata": {},
   "source": [
    "# 多轮对话演示\n",
    "\n",
    "扩展上面的代码，支持多轮对话。这意味着模型可以记住上下文，从而生成更连贯的回答。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85bb7a3-b42e-4888-b5cd-470b196106e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(messages):\n",
    "    client = OpenAI(\n",
    "        api_key=os.getenv('OPENAI_API_KEY'), \n",
    "        base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    )\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"qwen-turbo\",\n",
    "        messages=messages\n",
    "    )\n",
    "    return completion\n",
    "\n",
    "# 初始化对话历史\n",
    "messages = [{'role': 'system', 'content': 'You are a helpful assistant.'}]\n",
    "\n",
    "# 进行多轮对话\n",
    "for i in range(3):\n",
    "    user_input = input(\"请输入你的问题：\")\n",
    "    \n",
    "    # 将用户问题添加到对话历史中\n",
    "    messages.append({'role': 'user', 'content': user_input})\n",
    "    \n",
    "    # 获取模型回复并打印\n",
    "    assistant_output = get_response(messages).choices[0].message.content\n",
    "    print(f'模型回复：{assistant_output}')\n",
    "    \n",
    "    # 将模型的回复也添加到对话历史中\n",
    "    messages.append({'role': 'assistant', 'content': assistant_output})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81b46ed-df4a-455d-be25-f10914ab4e08",
   "metadata": {},
   "source": [
    "# 流式输出演示\n",
    "\n",
    "流式输出允许我们实时查看模型生成的回答，而不是等待最终结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5207ea23-f336-4c76-bc7d-c5637796fdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现流式输出\n",
    "def get_response_stream():\n",
    "    client = OpenAI(\n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "        base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    )\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"qwen-turbo\",\n",
    "        messages=[{'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "                  {'role': 'user', 'content': '你是谁？'}],\n",
    "        stream=True,\n",
    "        stream_options={\"include_usage\": True}\n",
    "    )\n",
    "    \n",
    "    # 实时输出生成的结果\n",
    "    for chunk in completion:\n",
    "        print(chunk.model_dump_json())\n",
    "\n",
    "# 调用流式输出函数\n",
    "get_response_stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbac289-276e-4b60-8d1c-b7eef5e3da0b",
   "metadata": {},
   "source": [
    "# 总结与扩展学习\n",
    "\n",
    "恭喜你完成了API的使用！在这个notebook中，你学习了如何与大语言模型API进行交互，如何设置环境变量，如何实现单轮和多轮对话，并了解了流式输出的概念。\n",
    "\n",
    "如果你对AI和生成式人工智能感兴趣，推荐你观看李宏毅老师的课程：\n",
    "- [生成式人工智能导论-视频](https://www.bilibili.com/video/BV1BJ4m1e7g8)\n",
    "- [课程主页](https://speech.ee.ntu.edu.tw/~hylee/genai/2024-spring.php)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75c266f-d51c-4690-b280-852151b4b19d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
