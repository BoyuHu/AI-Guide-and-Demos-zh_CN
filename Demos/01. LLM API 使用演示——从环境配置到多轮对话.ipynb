{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f01cd25-5a0f-40d5-a48f-990022340c09",
   "metadata": {},
   "source": [
    "# 简介\n",
    "\n",
    "> 指导文章：[01. 初识 LLM API：环境配置与多轮对话演示](https://github.com/Hoper-J/LLM-Guide-and-Demos/blob/master/Guide/01.%20初识%20LLM%20API：环境配置与多轮对话演示.md)\n",
    "\n",
    "在这个 Notebook 中，我们将展示如何使用大语言模型（LLM）API，通过简单的 API 调用，演示如何与大模型进行交互。这是对 API 基础使用的一个演示，不涉及构建 AI 应用。\n",
    "\n",
    "在线链接：[Kaggle](https://www.kaggle.com/code/aidemos/01-llm-api) | [Colab](https://colab.research.google.com/drive/1jFC_WIec7KW08GBxHuEHikcXWbbv3gSh?usp=share_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9688f10-a828-498a-ae34-2458372eeac0",
   "metadata": {},
   "source": [
    "# 环境变量配置\n",
    "\n",
    "为了保护API密钥的安全，需要将其设置为环境变量。环境变量允许我们在不将敏感信息写入代码的情况下访问它们。\n",
    "\n",
    "你可以通过两种方式之一来设置环境变量：\n",
    "1. 在终端中设置环境变量。\n",
    "2. 在 Python 脚本中设置环境变量。\n",
    "\n",
    "这里直接在 Python 中进行设置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcc60ff-c2f1-4a4d-89ba-703ce064aa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 此方法仅在当前 Python 程序或 Notebook 中有效，其他程序或 Notebook 不会共享此设置。\n",
    "# 国内大模型开启了新的篇章，考虑到以后可能会进行多模型的 API 输出对比，不再固定命名为 `OPENAI_API_KEY`。\n",
    "import os\n",
    "\n",
    "# 阿里云（通义千问） API 密钥在 OPENAI_API_KEY 设置\n",
    "os.environ['OPENAI_API_KEY'] = 'your-api-key'\n",
    "\n",
    "# 智谱 API\n",
    "os.environ['ZHIPUAI_API_KEY'] = 'your-api-key'\n",
    "\n",
    "# DEEPSEEK API\n",
    "os.environ['DEEPSEEK_API_KEY'] = 'your-api-key'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde759d2-84d8-47d8-afb9-b60eb8b8c8c8",
   "metadata": {},
   "source": [
    "# 获取环境变量\n",
    "\n",
    "使用 `os.getenv()` 函数来获取环境变量的值，这样我们可以在代码中安全地访问API密钥。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2537743-ddf7-409f-a0b7-9907fc3c171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取API密钥\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "# api_key = os.getenv('ZHIPUAI_API_KEY')\n",
    "# api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "\n",
    "# 打印密钥以确认它被成功读取\n",
    "print(api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa90edf1-6557-4d2e-bc9f-0cd32ee2399a",
   "metadata": {},
   "source": [
    "# 安装所需库\n",
    "\n",
    "接下来，我们需要安装 openai 库，用于与阿里云的大模型 API 进行交互。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8861d904-182e-459b-8d68-bcb643d11615",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai\n",
    "#!pip install 'httpx<0.28.0' # 降级 httpx 以解决关键字 'proxies' 被移除的问题，最新的 openai 库不会引发该问题，故默认注释"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8337b2-a8d3-4f39-a278-71749a9e5763",
   "metadata": {},
   "source": [
    "根据 API 平台执行后续对应的代码块。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bec3a1-907b-45f8-b86f-e76dfbd11838",
   "metadata": {},
   "source": [
    "# 单轮对话演示\n",
    "\n",
    "在这一部分，我们将通过API调用构建一个简单的单轮对话，你可以输入一个问题，模型将会返回一个响应。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c001e93-89f5-4764-aeb3-255f050e2099",
   "metadata": {},
   "source": [
    "## 阿里 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32ed729-5af0-41f1-bba5-ca31b04b833e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# 定义函数来获取模型响应\n",
    "def get_response():\n",
    "    client = OpenAI(\n",
    "        api_key=os.getenv('OPENAI_API_KEY'),  # 获取环境变量中的API密钥\n",
    "        base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",  # 使用阿里云大模型API\n",
    "    )\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"qwen-turbo\",\n",
    "        messages=[\n",
    "            {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "            {'role': 'user', 'content': '你是谁？'}\n",
    "        ]\n",
    "    )\n",
    "    print(completion.model_dump_json())\n",
    "\n",
    "# 调用函数进行对话\n",
    "get_response()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bb56a4-3e75-429a-99fb-59596527af15",
   "metadata": {},
   "source": [
    "## 智谱 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba141c08-61fd-490b-b67a-44c324a68763",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "def get_response():\n",
    "    client = OpenAI(\n",
    "        api_key=os.getenv('ZHIPUAI_API_KEY'),\n",
    "        base_url=\"https://open.bigmodel.cn/api/paas/v4\",\n",
    "    )\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"glm-4-plus\",\n",
    "        messages=[\n",
    "            {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "            {'role': 'user', 'content': '你是谁？'}]\n",
    "        )\n",
    "    print(completion.model_dump_json())\n",
    "\n",
    "get_response()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3d8202-7966-4b90-bb21-7b1eabf0c856",
   "metadata": {},
   "source": [
    "## DeepSeek API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23857fab-e807-433f-b3a6-b2e36f21e6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "def get_response():\n",
    "    client = OpenAI(\n",
    "        api_key=os.getenv('DEEPSEEK_API_KEY'), # 1\n",
    "        base_url=\"https://api.deepseek.com\", # 2\n",
    "    )\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\", # 3\n",
    "        messages=[\n",
    "            {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "            {'role': 'user', 'content': '你是谁？'}]\n",
    "        )\n",
    "    print(completion.model_dump_json())\n",
    "\n",
    "get_response()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bca8c3f-bde7-404e-ba2b-2180c3d62118",
   "metadata": {},
   "source": [
    "# 多轮对话演示\n",
    "\n",
    "扩展上面的代码，支持多轮对话。这意味着模型可以记住上下文，从而生成更连贯的回答。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbabc1a1-875a-4781-80d8-a8ebcb4772f3",
   "metadata": {},
   "source": [
    "## 阿里 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85bb7a3-b42e-4888-b5cd-470b196106e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(messages):\n",
    "    client = OpenAI(\n",
    "        api_key=os.getenv('OPENAI_API_KEY'), \n",
    "        base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    )\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"qwen-turbo\",\n",
    "        messages=messages\n",
    "    )\n",
    "    return completion\n",
    "\n",
    "# 初始化对话历史\n",
    "messages = [{'role': 'system', 'content': 'You are a helpful assistant.'}]\n",
    "\n",
    "# 进行多轮对话\n",
    "for i in range(3):\n",
    "    user_input = input(\"请输入你的问题：\")\n",
    "    \n",
    "    # 将用户问题添加到对话历史中\n",
    "    messages.append({'role': 'user', 'content': user_input})\n",
    "    \n",
    "    # 获取模型回复并打印\n",
    "    assistant_output = get_response(messages).choices[0].message.content\n",
    "    print(f'模型回复：{assistant_output}')\n",
    "    \n",
    "    # 将模型的回复也添加到对话历史中\n",
    "    messages.append({'role': 'assistant', 'content': assistant_output})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d433bf0e-3db1-4d9b-b5f7-40bc2167e086",
   "metadata": {},
   "source": [
    "## 智谱 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5377fc54-d7e5-46a8-a82c-51c949bb4f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "def get_response(messages):\n",
    "    client = OpenAI(\n",
    "        api_key=os.getenv('ZHIPUAI_API_KEY'), \n",
    "        base_url=\"https://open.bigmodel.cn/api/paas/v4\",\n",
    "    )\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"glm-4-plus\",\n",
    "        messages=messages\n",
    "        )\n",
    "    return completion\n",
    "\n",
    "messages = [{'role': 'system', 'content': 'You are a helpful assistant.'}]\n",
    "# 您可以自定义设置对话轮数，当前为3\n",
    "for i in range(3):\n",
    "    user_input = input(\"请输入：\")\n",
    "    \n",
    "    # 将用户问题信息添加到messages列表中，这部分等价于之前的单轮对话\n",
    "    messages.append({'role': 'user', 'content': user_input})\n",
    "    assistant_output = get_response(messages).choices[0].message.content\n",
    "    \n",
    "    # 将大模型的回复信息添加到messages列表中，这里是历史记录，保存上下文\n",
    "    messages.append({'role': 'assistant', 'content': assistant_output})\n",
    "    print(f'用户输入：{user_input}')\n",
    "    print(f'模型输出：{assistant_output}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcb045f-3fca-4a9e-9953-2ad75a513afd",
   "metadata": {},
   "source": [
    "## DeepSeek API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd84b44d-8c32-46fc-9a10-df397bb32e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "def get_response(messages):\n",
    "    client = OpenAI(\n",
    "        api_key=os.getenv('DEEPSEEK_API_KEY'), \n",
    "        base_url=\"https://api.deepseek.com\",\n",
    "    )\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=messages\n",
    "        )\n",
    "    return completion\n",
    "\n",
    "messages = [{'role': 'system', 'content': 'You are a helpful assistant.'}]\n",
    "# 您可以自定义设置对话轮数，当前为3\n",
    "for i in range(3):\n",
    "    user_input = input(\"请输入：\")\n",
    "    \n",
    "    # 将用户问题信息添加到messages列表中，这部分等价于之前的单轮对话\n",
    "    messages.append({'role': 'user', 'content': user_input})\n",
    "    assistant_output = get_response(messages).choices[0].message.content\n",
    "    \n",
    "    # 将大模型的回复信息添加到messages列表中，这里是历史记录，保存上下文\n",
    "    messages.append({'role': 'assistant', 'content': assistant_output})\n",
    "    print(f'用户输入：{user_input}')\n",
    "    print(f'模型输出：{assistant_output}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81b46ed-df4a-455d-be25-f10914ab4e08",
   "metadata": {},
   "source": [
    "# 流式输出演示\n",
    "\n",
    "流式输出允许我们实时查看模型生成的回答，而不是等待最终结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3154f465-cbe0-44cb-b85a-85fa48f063d6",
   "metadata": {},
   "source": [
    "## 阿里 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5207ea23-f336-4c76-bc7d-c5637796fdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现流式输出\n",
    "def get_response_stream():\n",
    "    client = OpenAI(\n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "        base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    )\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"qwen-turbo\",\n",
    "        messages=[{'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "                  {'role': 'user', 'content': '你是谁？'}],\n",
    "        stream=True,\n",
    "        stream_options={\"include_usage\": True}\n",
    "    )\n",
    "    \n",
    "    # 实时输出生成的结果\n",
    "    for chunk in completion:\n",
    "        print(chunk.model_dump_json())\n",
    "\n",
    "# 调用流式输出函数\n",
    "get_response_stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902072d5-aeee-4846-a0de-8f43abcd6692",
   "metadata": {},
   "source": [
    "## 智谱 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415c0883-c6b1-4b4a-920b-2b90e3625706",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "def get_response():\n",
    "    client = OpenAI(\n",
    "        api_key=os.getenv(\"ZHIPUAI_API_KEY\"),\n",
    "        base_url=\"https://open.bigmodel.cn/api/paas/v4\",\n",
    "    )\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"glm-4-plus\",\n",
    "        messages=[{'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "                  {'role': 'user', 'content': '你是谁？'}],\n",
    "        stream=True,\n",
    "        # 可选，配置以后会在流式输出的最后一行展示token使用信息\n",
    "        stream_options={\"include_usage\": True}\n",
    "        )\n",
    "    for chunk in completion:\n",
    "        print(chunk.model_dump_json())\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    get_response()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ead8eca-d36b-45fc-b73c-78044a1f802a",
   "metadata": {},
   "source": [
    "## DeepSeek API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47961125-d1b4-4f32-aecd-ac8235130854",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "def get_response():\n",
    "    client = OpenAI(\n",
    "        api_key=os.getenv(\"DEEPSEEK_API_KEY\"),\n",
    "        base_url=\"https://api.deepseek.com\",\n",
    "    )\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=[{'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "                  {'role': 'user', 'content': '你是谁？'}],\n",
    "        stream=True,\n",
    "        # 可选，配置以后会在流式输出的最后一行展示token使用信息\n",
    "        stream_options={\"include_usage\": True}\n",
    "        )\n",
    "    for chunk in completion:\n",
    "        print(chunk.model_dump_json())\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    get_response()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbac289-276e-4b60-8d1c-b7eef5e3da0b",
   "metadata": {},
   "source": [
    "# 总结与扩展学习\n",
    "\n",
    "恭喜你完成了API的使用！在这个notebook中，我们学习了如何与大语言模型API进行交互，如何设置环境变量，如何实现单轮和多轮对话，并了解了流式输出的概念。\n",
    "\n",
    "如果对AI和生成式人工智能感兴趣，推荐观看李宏毅老师的课程：\n",
    "- [生成式人工智能导论-视频](https://www.bilibili.com/video/BV1BJ4m1e7g8)\n",
    "- [课程主页](https://speech.ee.ntu.edu.tw/~hylee/genai/2024-spring.php)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75c266f-d51c-4690-b280-852151b4b19d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
